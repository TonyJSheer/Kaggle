{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-79553fbdf1c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# import packages for hyperparameters tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Set Matplotlib defaults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'fmax'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import exp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    mi_scores = mutual_info_regression(X, y, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(\n",
    "        100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    # Reading File\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Reducing Size by Optimizing Dtypes of columns\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    # Converting Bool cols into integer\n",
    "    bool_cols = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if df[col].dtypes == bool:\n",
    "            bool_cols.append(i)\n",
    "    df.iloc[:, bool_cols] = df.iloc[:, bool_cols].astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2189.64 MB\n",
      "Memory usage after optimization is: 505.45 MB\n",
      "Decreased by 76.9%\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"train.csv\"\n",
    "df_train = import_data(train_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_smaller = df_train.sample(random_state=1, n=10000, axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.loc[:,\"f0\":\"f284\"], df_train[\"target\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "mi_scores = make_mi_scores(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:, mi_scores > 0]\n",
    "X_test = X_test.loc[:, mi_scores > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = dict(\n",
    "    #objective = \"binary\",\n",
    "    eval_metric = roc_auc_score,\n",
    "    max_depth=2,           # maximum depth of each tree - try 2 to 10\n",
    "    learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n",
    "    n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "    min_child_weight=2,    # minimum number of houses in a leaf - try 1 to 10\n",
    "    colsample_bytree=0.2,  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "    subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "    reg_alpha=3,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "    reg_lambda=2.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "    num_parallel_tree=1,   # set > 1 for boosted random forests\n",
    "    use_label_encoder=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", log(0.001), log(0.03)), # effect of each tree - try 0.0001 to 0.1\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 2, 10, 1), # maximum depth of each tree - try 2 to 10\n",
    "    \"gamma\": hp.uniform (\"gamma\", 1,9),\n",
    "    \"reg_alpha\" : hp.uniform(\"reg_alpha\", 2,10), # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "    \"reg_lambda\" : hp.uniform(\"reg_lambda\", 2,100), # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "    \"colsample_bytree\" : hp.uniform(\"colsample_bytree\", 0.1,1), # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "    \"min_child_weight\" : hp.quniform(\"min_child_weight\", 0, 100, 1), # minimum number of houses in a leaf - try 1 to 10\n",
    "    \"n_estimators\": 1000, #  number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "    \"subsample\":0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "    \"seed\": 0,\n",
    "    \"use_label_encoder\":False,\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model=XGBRegressor(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric = \"auc\",\n",
    "        max_depth=int(space['max_depth']),           # maximum depth of each tree - try 2 to 10\n",
    "        learning_rate=0.02,  # effect of each tree - try 0.0001 to 0.1\n",
    "        n_estimators=space['n_estimators'],     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "        min_child_weight=int(space['min_child_weight']),    # minimum number of houses in a leaf - try 1 to 10\n",
    "        colsample_bytree=int(space['colsample_bytree']),  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "        subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "        reg_alpha=int(space['reg_alpha']),         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "        reg_lambda=int(space['reg_lambda']),        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "        gamma = space['gamma'],\n",
    "        num_parallel_tree=1,   # set > 1 for boosted random forests\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        #eval_set=evaluation, \n",
    "        #eval_metric=\"auc\",\n",
    "        #early_stopping_rounds=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    accuracy = roc_auc_score(y_test, model.predict(X_test))\n",
    "    print (f\"SCORE:{accuracy}\")\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7856667856667856"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "# X_test = df_test.loc[:,\"f0\":\"f284\"]\n",
    "# print(X_test.loc[:100, mi_scores > 0.0])\n",
    "predictions = model.predict(X_test)\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:0.8096133096133097\n",
      "SCORE:0.8124123124123125\n",
      "SCORE:0.8033238033238034\n",
      "SCORE:0.8036613036613037\n",
      "SCORE:0.817903817903818\n",
      "SCORE:0.8156918156918158\n",
      "SCORE:0.7994772994772994\n",
      "SCORE:0.8186838186838187\n",
      "SCORE:0.8115598115598116\n",
      "SCORE:0.8181118181118181\n",
      "SCORE:0.8023108023108023\n",
      "SCORE:0.8183998183998183\n",
      "SCORE:0.797025297025297\n",
      "SCORE:0.8159118159118159\n",
      "SCORE:0.7928972928972928\n",
      "SCORE:0.8170578170578171\n",
      "SCORE:0.8152178152178151\n",
      "SCORE:0.8185718185718186\n",
      "SCORE:0.8115358115358116\n",
      "SCORE:0.8184483184483182\n",
      "SCORE:0.8176548176548176\n",
      "SCORE:0.8175328175328174\n",
      "SCORE:0.8173888173888173\n",
      "SCORE:0.818057818057818\n",
      "SCORE:0.8186843186843187\n",
      "SCORE:0.8176448176448177\n",
      "SCORE:0.8175698175698176\n",
      "SCORE:0.8134543134543135\n",
      "SCORE:0.8179458179458179\n",
      "SCORE:0.8168908168908169\n",
      "SCORE:0.8184013184013184\n",
      "SCORE:0.8153648153648154\n",
      "SCORE:0.8178728178728178\n",
      "SCORE:0.8182198182198182\n",
      "SCORE:0.816958816958817\n",
      "SCORE:0.8102133102133102\n",
      "SCORE:0.8176493176493176\n",
      "SCORE:0.817012317012317\n",
      "SCORE:0.8178378178378177\n",
      "SCORE:0.8178438178438179\n",
      "SCORE:0.8183568183568183\n",
      "SCORE:0.8183688183688183\n",
      "SCORE:0.8163618163618164\n",
      "SCORE:0.8188208188208188\n",
      "SCORE:0.8186253186253186\n",
      "SCORE:0.8165158165158166\n",
      "SCORE:0.8189938189938191\n",
      "SCORE:0.8144078144078144\n",
      "SCORE:0.8188538188538188\n",
      "SCORE:0.8192093192093193\n",
      "SCORE:0.8184118184118184\n",
      "SCORE:0.8188158188158188\n",
      "SCORE:0.8186443186443186\n",
      "SCORE:0.814941814941815\n",
      "SCORE:0.8144798144798144\n",
      "SCORE:0.8146108146108145\n",
      "SCORE:0.817040817040817\n",
      "SCORE:0.8188313188313188\n",
      "SCORE:0.8181638181638182\n",
      "SCORE:0.818081818081818\n",
      "SCORE:0.8192338192338192\n",
      "SCORE:0.8189358189358189\n",
      "SCORE:0.8133283133283133\n",
      "SCORE:0.8002523002523003\n",
      "SCORE:0.8184888184888186\n",
      "SCORE:0.8184868184868185\n",
      "SCORE:0.8188228188228188\n",
      "SCORE:0.818884818884819\n",
      "SCORE:0.8187258187258186\n",
      "SCORE:0.8177638177638178\n",
      "SCORE:0.818036818036818\n",
      "SCORE:0.8172848172848173\n",
      "SCORE:0.8181818181818181\n",
      "SCORE:0.8183788183788183\n",
      "SCORE:0.8178413178413179\n",
      "SCORE:0.8156738156738158\n",
      "SCORE:0.8192593192593193\n",
      "SCORE:0.8187498187498188\n",
      "SCORE:0.8178618178618178\n",
      "SCORE:0.8178783178783178\n",
      "SCORE:0.8136028136028136\n",
      "SCORE:0.8184608184608184\n",
      "SCORE:0.8146053146053146\n",
      "SCORE:0.8180458180458181\n",
      "SCORE:0.8183778183778183\n",
      "SCORE:0.8118318118318119\n",
      "SCORE:0.8167168167168166\n",
      "SCORE:0.8180418180418181\n",
      "SCORE:0.818912818912819\n",
      "SCORE:0.8173338173338174\n",
      "SCORE:0.8007138007138006\n",
      "SCORE:0.817981817981818\n",
      "SCORE:0.8156158156158155\n",
      "SCORE:0.8178868178868179\n",
      "SCORE:0.818045818045818\n",
      "SCORE:0.8157628157628158\n",
      "SCORE:0.817953317953318\n",
      "SCORE:0.8179728179728181\n",
      "SCORE:0.8188838188838189\n",
      "SCORE:0.818098818098818\n",
      "100%|██████████| 100/100 [05:19<00:00,  3.19s/trial, best loss: -0.8192593192593193]\n",
      "\n",
      "The best hyperparameters are : \n",
      "{'colsample_bytree': 0.940352349670067, 'gamma': 5.959481970038466, 'learning_rate': 0.008031119376641707, 'max_depth': 2.0, 'min_child_weight': 51.0, 'reg_alpha': 7.188856124326307, 'reg_lambda': 74.6693399560162}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"\\nThe best hyperparameters are : \")\n",
    "print(best_hyperparams)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e0a052cdeffa2e44748640be9c407ae1444ac64670cf6a78a6c8f94ed316213"
  },
  "kernelspec": {
   "display_name": "Python 3.6.0 64-bit ('venv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
