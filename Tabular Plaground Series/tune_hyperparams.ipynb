{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    mi_scores = mutual_info_regression(X, y, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(\n",
    "        100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    # Reading File\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Reducing Size by Optimizing Dtypes of columns\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    # Converting Bool cols into integer\n",
    "    bool_cols = []\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if df[col].dtypes == bool:\n",
    "            bool_cols.append(i)\n",
    "    df.iloc[:, bool_cols] = df.iloc[:, bool_cols].astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2189.64 MB\n",
      "Memory usage after optimization is: 505.45 MB\n",
      "Decreased by 76.9%\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"train.csv\"\n",
    "df_train = import_data(train_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_smaller = df_train.sample(random_state=1, n=10000, axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.loc[:,\"f0\":\"f284\"], df_train[\"target\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(X_train.iloc[:50000], y_train.iloc[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:, mi_scores > 0]\n",
    "X_test = X_test.loc[:, mi_scores > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = dict(\n",
    "    objective = \"binary:logistic\",\n",
    "    eval_metric = \"auc\",\n",
    "    max_depth=3,           # maximum depth of each tree - try 2 to 10\n",
    "    learning_rate=0.015,    # effect of each tree - try 0.0001 to 0.1\n",
    "    n_estimators=5000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "    min_child_weight=75,    # minimum number of houses in a leaf - try 1 to 10\n",
    "    colsample_bytree=0.5,  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "    subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "    gamma=8,\n",
    "    reg_alpha=8,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "    reg_lambda=80,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "    num_parallel_tree=1,   # set > 1 for boosted random forests\n",
    "    use_label_encoder=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", log(0.01), log(0.03)), # effect of each tree - try 0.0001 to 0.1\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 2, 5, 1), # maximum depth of each tree - try 2 to 10\n",
    "    \"gamma\": hp.uniform (\"gamma\", 7, 9),\n",
    "    \"reg_alpha\" : hp.uniform(\"reg_alpha\", 5,7), # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "    \"reg_lambda\" : hp.uniform(\"reg_lambda\", 70,100), # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "    \"colsample_bytree\" : hp.uniform(\"colsample_bytree\", 0.2,0.6), # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "    \"min_child_weight\" : hp.quniform(\"min_child_weight\", 75, 90, 1), # minimum number of houses in a leaf - try 1 to 10\n",
    "    \"n_estimators\": hp.uniform(\"n_estimators\", 4500, 5500), #  number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "    \"subsample\": hp.uniform(\"n_estimators\", 0.2, 1),         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "    \"seed\": 0,\n",
    "    \"use_label_encoder\":False,\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model=XGBRegressor(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric = \"auc\",\n",
    "        max_depth=int(space[\"max_depth\"]),           # maximum depth of each tree - try 2 to 10\n",
    "        learning_rate=space[\"learning_rate\"],  # effect of each tree - try 0.0001 to 0.1\n",
    "        n_estimators=int(space[\"n_estimators\"]),     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "        min_child_weight=int(space[\"min_child_weight\"]),    # minimum number of houses in a leaf - try 1 to 10\n",
    "        colsample_bytree=int(space[\"colsample_bytree\"]),  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "        subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "        reg_alpha=int(space[\"reg_alpha\"]),         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "        reg_lambda=int(space[\"reg_lambda\"]),        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "        gamma = space[\"gamma\"],\n",
    "        num_parallel_tree=1,   # set > 1 for boosted random forests\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=evaluation, \n",
    "        #eval_metric=\"auc\",\n",
    "        #early_stopping_rounds=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    accuracy = roc_auc_score(y_test, model.predict(X_test))\n",
    "    print (f\"SCORE:{accuracy}\")\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479999683931316"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(**xgb_params)\n",
    "model.fit(X_train.iloc[:10000, :], y_train[:10000])\n",
    "# X_test = df_test.loc[:,\"f0\":\"f284\"]\n",
    "# print(X_test.loc[:100, mi_scores > 0.0])\n",
    "predictions = model.predict(X_test)\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f32\n",
      "f71\n",
      "f231\n",
      "f18\n",
      "f37\n",
      "f42\n",
      "f202\n",
      "f240\n",
      "f185\n",
      "f69\n",
      "f58\n",
      "f211\n",
      "f9\n",
      "f53\n",
      "f212\n",
      "f238\n"
     ]
    }
   ],
   "source": [
    "Xx_train = X_train.copy()\n",
    "Xx_test = X_test.copy()\n",
    "features_to_log = [\n",
    "    \"f2\",    \"f9\",    \"f18\",    \"f29\",    \"f31\",    \"f32\",    \"f37\",    \"f42\",    \"f47\",    \"f50\",    \"f53\",    \"f55\",    \"f58\",    \"f63\",\n",
    "    \"f64\",    \"f69\",    \"f71\",    \"f87\",     \"f109\",    \"f112\",    \"f118\",    \"f123\",    \"f128\",    \"f175\",    \"f176\",    \"f183\",    \"f185\",\n",
    "    \"f200\",    \"f202\",    \"f211\",    \"f212\",    \"f231\",    \"f236\",    \"f238\",    \"f240\",\n",
    "]\n",
    "for feature in set(Xx_train.columns).intersection(features_to_log):\n",
    "    print(feature)\n",
    "    Xx_train[feature] = X_train[feature].map(lambda x: log(x + 0.0001))\n",
    "for feature in set(Xx_train.columns).intersection(features_to_log):\n",
    "    Xx_test[feature] = X_test[feature].map(lambda x: log(x + 0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8335109435337977\n"
     ]
    }
   ],
   "source": [
    "lmodel = LinearRegression()  # coef_, feature_names_in_\n",
    "lmodel.fit(Xx_train, y_train)\n",
    "predictions = lmodel.predict(Xx_test.loc[:,mi_scores > 0])\n",
    "print(roc_auc_score(y_test, predictions))\n",
    "\n",
    "logmodel = LogisticRegression(max_iter=10000)\n",
    "logmodel.fit(X_train, y_train)\n",
    "predictions = logmodel.predict(X_test.loc[:,mi_scores > 0])\n",
    "print(roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 148)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8465985399233031\n"
     ]
    }
   ],
   "source": [
    "#predictions1 = model.predict(X_test)\n",
    "#predictions2 = lmodel.predict(X_test)\n",
    "# X_test['a'] = predictions1\n",
    "# X_test['b'] = predictions2\n",
    "\n",
    "model3 = XGBRegressor(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric = \"auc\",\n",
    ")\n",
    "model3.fit(X_test.loc[:,['a','b']].iloc[:170000,:], y_test[:170000])\n",
    "print(roc_auc_score(y_test[170000:], model3.predict(X_test.loc[:,['a','b']].iloc[170000:,:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7651669199991975\n"
     ]
    }
   ],
   "source": [
    "predictions2 = map(lambda x: min(round(x), 1), predictions)\n",
    "print(roc_auc_score(y_test, list(map(lambda x: min(round(x), 1), predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in map(lambda x: x**2, [1,2,3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.58445877, 16), (0.06848967, 94), (0.03419731, 40), (0.02287083, 35), (0.018578827, 72), (0.0151742315, 82), (0.011422357, 46), (0.007808696, 5), (0.007405527, 52), (0.0073559163, 127), (0.007032689, 9), (0.0060448926, 45), (0.0059362054, 71), (0.005806316, 2), (0.005741549, 101), (0.005358314, 14), (0.005191039, 15), (0.0050935843, 43), (0.0050609796, 42), (0.0050144284, 107), (0.0047325264, 34), (0.004626298, 111), (0.0044322186, 54), (0.0043406705, 133), (0.004033894, 1), (0.0038640331, 65), (0.0037717612, 135), (0.0035309475, 56), (0.003530528, 13), (0.003343811, 31), (0.0033052503, 59), (0.0032556343, 103), (0.0030365034, 80), (0.0029186457, 3), (0.0027143513, 11), (0.0025116766, 75), (0.0024716018, 51), (0.0024282, 44), (0.0024144377, 74), (0.0023313363, 78), (0.0023146966, 113), (0.002263072, 67), (0.0022607925, 81), (0.0020896245, 55), (0.0019593267, 32), (0.0018448781, 121), (0.0016720839, 29), (0.0016541507, 10), (0.0016391496, 76), (0.0016262864, 4), (0.0015932797, 41), (0.0015880811, 106), (0.0015795616, 83), (0.0015279636, 92), (0.001458595, 139), (0.0013959453, 62), (0.0013735031, 63), (0.0013648713, 91), (0.001363784, 49), (0.0013305396, 123), (0.0013150676, 19), (0.0012964398, 100), (0.0012858225, 24), (0.0012580196, 118), (0.001256529, 64), (0.0012485627, 37), (0.0012416294, 137), (0.0012409299, 97), (0.0012360966, 8), (0.0012221829, 120), (0.0012122797, 87), (0.0011504549, 129), (0.0011338566, 36), (0.0011224669, 125), (0.0010881716, 102), (0.0010707439, 77), (0.0010577216, 115), (0.0010467051, 110), (0.001040368, 142), (0.0010172527, 26), (0.000984108, 68), (0.000975477, 70), (0.0009743108, 79), (0.00095445575, 112), (0.0009496838, 48), (0.0009449028, 47), (0.00091648643, 85), (0.0008924573, 18), (0.0008883484, 126), (0.00087953423, 25), (0.00087899005, 33), (0.0008654433, 57), (0.00086142356, 20), (0.00085821777, 86), (0.00085554435, 140), (0.0008216402, 12), (0.0007936726, 53), (0.00078937097, 124), (0.0007866948, 6), (0.00076090544, 23), (0.0007520041, 30), (0.0007426222, 138), (0.0007285857, 60), (0.000717132, 114), (0.00071147445, 50), (0.0007107252, 38), (0.00069474685, 22), (0.0006899909, 145), (0.00067769433, 98), (0.00067223597, 141), (0.00066845375, 27), (0.00063651317, 96), (0.0006348085, 89), (0.00060397456, 93), (0.0005955308, 132), (0.0005806283, 69), (0.0005687179, 7), (0.0005500558, 144), (0.00054453773, 66), (0.0005330445, 119), (0.00052800844, 131), (0.0005270597, 21), (0.0005215848, 0), (0.0005215386, 99), (0.00051647105, 73), (0.0004932236, 122), (0.00046762137, 61), (0.0004600745, 17), (0.00044908418, 28), (0.0004449046, 90), (0.00044441194, 88), (0.00044315372, 58), (0.00043961278, 95), (0.00043887884, 116), (0.00042900708, 105), (0.0004107136, 104), (0.00040577902, 117), (0.00040244102, 84), (0.00040120093, 39), (0.00038759082, 109), (0.00037795008, 108), (0.00034695966, 130), (0.00021542545, 143), (0.00019150025, 128), (1.0199816e-05, 136), (2.4531685e-06, 134)]\n"
     ]
    }
   ],
   "source": [
    "a = sorted(((coef, i)for i, coef in enumerate(model.feature_importances_)), reverse=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.4895005, 72), (0.28519273, 2), (0.23762928, 15), (0.23277172, 14), (0.23074074, 45), (0.20273374, 65), (0.17734738, 56), (0.17332348, 82), (0.16113313, 13), (0.15722449, 59), (0.1415964, 44), (0.13130072, 29), (0.1020079, 64), (0.09302723, 10), (0.091217436, 62), (0.08320858, 54), (0.08135526, 32), (0.06443855, 106), (0.06384713, 87), (0.06078648, 121), (0.06039912, 124), (0.056001708, 51), (0.046479136, 126), (0.043971904, 55), (0.04039809, 63), (0.03936003, 8), (0.037410572, 18), (0.03605589, 33), (0.03318128, 96), (0.031029081, 120), (0.02978688, 86), (0.028920736, 0), (0.028785594, 66), (0.028783023, 30), (0.027883528, 122), (0.027050273, 93), (0.025730625, 12), (0.023955341, 25), (0.02150826, 50), (0.021487061, 23), (0.02039779, 74), (0.01853353, 53), (0.01827091, 98), (0.01723714, 60), (0.01657787, 116), (0.015267471, 22), (0.014667569, 73), (0.009432383, 83), (0.009048467, 95), (0.008044459, 28), (0.007877145, 38), (0.0076247957, 88), (0.0067775557, 17), (0.0057829116, 108), (0.004374142, 58), (0.0020622965, 69), (0.0015962012, 136), (0.0008528223, 61), (0.0004172325, 130), (0.0003241375, 134), (0.00017703278, 114), (-0.00024041813, 117), (-0.00041531026, 143), (-0.0007033795, 128), (-0.0011222535, 105), (-0.0019982606, 131), (-0.0021114014, 132), (-0.0022226274, 84), (-0.002608127, 125), (-0.002684921, 138), (-0.0028653815, 144), (-0.004025668, 140), (-0.0045298785, 145), (-0.0047317, 39), (-0.0049479306, 141), (-0.005291486, 48), (-0.0059468024, 129), (-0.006839834, 142), (-0.007475972, 139), (-0.008335631, 137), (-0.0098713655, 109), (-0.0101194605, 79), (-0.010541044, 89), (-0.010850348, 6), (-0.011847075, 57), (-0.012705028, 7), (-0.01409855, 90), (-0.015175989, 104), (-0.01584239, 99), (-0.019982483, 85), (-0.020028142, 21), (-0.020650461, 81), (-0.021707557, 135), (-0.021716967, 133), (-0.022201516, 77), (-0.02220194, 36), (-0.022949385, 119), (-0.023358826, 37), (-0.02385301, 27), (-0.02546481, 118), (-0.028237872, 102), (-0.02978576, 78), (-0.03211833, 49), (-0.033069838, 112), (-0.034186922, 75), (-0.034326486, 123), (-0.036797166, 26), (-0.036988895, 24), (-0.03896843, 127), (-0.04053452, 4), (-0.041523516, 20), (-0.04223232, 115), (-0.04260124, 100), (-0.043536656, 92), (-0.044282466, 91), (-0.04889836, 70), (-0.051195808, 97), (-0.05817954, 47), (-0.06791727, 19), (-0.070622094, 76), (-0.071389474, 113), (-0.07228114, 41), (-0.073797956, 67), (-0.07615582, 80), (-0.07938377, 43), (-0.08974687, 110), (-0.0905584, 103), (-0.09266553, 11), (-0.098012604, 68), (-0.11111294, 52), (-0.12382327, 101), (-0.12991606, 3), (-0.13385895, 1), (-0.15128209, 111), (-0.16181111, 31), (-0.162607, 9), (-0.16321634, 42), (-0.16941726, 34), (-0.17067337, 71), (-0.17826702, 5), (-0.17903367, 107), (-0.24170192, 35), (-0.2605372, 46), (-0.512154, 16), (-0.5357354, 40), (-0.6771387, 94)]\n"
     ]
    }
   ],
   "source": [
    "a = sorted(((coef, i)for i, coef in enumerate(lmodel.coef_)), reverse=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:0.8060374201662612\n",
      "SCORE:0.8057820007143253\n",
      "SCORE:0.8059321807888494\n",
      "SCORE:0.8059949513744904\n",
      "SCORE:0.8059178112077983\n",
      "SCORE:0.8060443899313222\n",
      "SCORE:0.8062959749249723\n",
      "SCORE:0.805849422410017\n",
      "SCORE:0.8058248517569222\n",
      "SCORE:0.8062248943713741\n",
      "SCORE:0.8002816464286098\n",
      "SCORE:0.8061633181383141\n",
      "SCORE:0.8053581452484161\n",
      "SCORE:0.8055882694456915\n",
      "SCORE:0.8064665466935608\n",
      "SCORE:0.8057249404410238\n",
      "SCORE:0.8058866901405487\n",
      "SCORE:0.8049977880697202\n",
      " 90%|█████████ | 18/20 [17:59<01:59, 59.95s/trial, best loss: -0.8064665466935608]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-bac413263ea8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                         \u001b[0mmax_evals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         trials = trials)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nThe best hyperparameters are : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             \u001b[0mtrials_save_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m         )\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[0mtrials_save_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         )\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             )\n\u001b[1;32m--> 907\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-677a4d45eb78>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(space)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m#eval_metric=\"auc\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m         )\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antho\\repos\\Kaggle\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1680\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 20,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"\\nThe best hyperparameters are : \")\n",
    "print(best_hyperparams)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e0a052cdeffa2e44748640be9c407ae1444ac64670cf6a78a6c8f94ed316213"
  },
  "kernelspec": {
   "display_name": "Python 3.6.0 64-bit ('venv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
